{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages (7.2.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 갯수:  332\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "print(\"가위 이미지 갯수: \", len(images))\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 갯수:  390\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "print(\"바위 이미지 갯수: \", len(images))\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 갯수:  419\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "print(\"보 이미지 갯수: \", len(images))\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper\n",
      "(1) 학습 이미지 갯수:  1141\n",
      "(1) 총 학습 이미지 갯수:  1141\n",
      "학습데이터(x_train)의 이미지 개수는 1141 입니다.\n",
      "x_train_total shape: (1141, 28, 28, 3)\n",
      "y_train_total shape: (1141,)\n",
      "\n",
      "(2) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_yesica\n",
      "(2) 학습 이미지 갯수:  2162\n",
      "(2) 총 학습 이미지 갯수:  3303\n",
      "학습데이터(x_train)의 이미지 개수는 2162 입니다.\n",
      "x_train_total shape: (3303, 28, 28, 3)\n",
      "y_train_total shape: (3303,)\n",
      "\n",
      "(3) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_min\n",
      "(3) 학습 이미지 갯수:  300\n",
      "(3) 총 학습 이미지 갯수:  5765\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train_total shape: (3603, 28, 28, 3)\n",
      "y_train_total shape: (3603,)\n",
      "\n",
      "(4) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_yoon\n",
      "(4) 학습 이미지 갯수:  300\n",
      "(4) 총 학습 이미지 갯수:  6065\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train_total shape: (3903, 28, 28, 3)\n",
      "y_train_total shape: (3903,)\n",
      "\n",
      "(5) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_minho\n",
      "(5) 학습 이미지 갯수:  600\n",
      "(5) 총 학습 이미지 갯수:  6665\n",
      "학습데이터(x_train)의 이미지 개수는 600 입니다.\n",
      "x_train_total shape: (4503, 28, 28, 3)\n",
      "y_train_total shape: (4503,)\n",
      "\n",
      "(6) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_back\n",
      "(6) 학습 이미지 갯수:  3195\n",
      "(6) 총 학습 이미지 갯수:  9860\n",
      "학습데이터(x_train)의 이미지 개수는 3195 입니다.\n",
      "x_train_total shape: (7698, 28, 28, 3)\n",
      "y_train_total shape: (7698,)\n",
      "\n",
      "(7) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_tae\n",
      "(7) 학습 이미지 갯수:  963\n",
      "(7) 총 학습 이미지 갯수:  10823\n",
      "학습데이터(x_train)의 이미지 개수는 963 입니다.\n",
      "x_train_total shape: (8661, 28, 28, 3)\n",
      "y_train_total shape: (8661,)\n",
      "\n",
      "(8) 학습 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_jaeho\n",
      "(8) 학습 이미지 갯수:  300\n",
      "(8) 총 학습 이미지 갯수:  11123\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train_total shape: (8961, 28, 28, 3)\n",
      "y_train_total shape: (8961,)\n",
      "\n",
      "\n",
      "(***) 테스트 이미지 디렉토리 경로:  /home/aiffel0042/aiffel/rock_scissor_paper_others\n",
      "테스트 총 이미지 갯수:  3916\n",
      "학습데이터(x_train)의 이미지 개수는 3916 입니다.\n",
      "x_test shape: (3916, 28, 28, 3)\n",
      "y_test shape: (3916,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    # number_of_data=1138   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "   # img_path = \"/home/aiffel0042/rock_scissor_paper/\"\n",
    "    \n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "  \n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "print(\"\\n(1) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images = num_images\n",
    "print(\"(1) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(1) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = x_train_norm\n",
    "y_train_total = y_train\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_yesica\"\n",
    "print(\"\\n(2) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(2) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(2) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_min\"\n",
    "total_num_images += num_images\n",
    "print(\"\\n(3) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(3) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(3) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_yoon\"\n",
    "print(\"\\n(4) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(4) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(4) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_minho\"\n",
    "print(\"\\n(5) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(5) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(5) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_back\"\n",
    "print(\"\\n(6) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(6) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(6) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_tae\"\n",
    "print(\"\\n(7) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(7) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(7) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "#train data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_jaeho\"\n",
    "print(\"\\n(8) 학습 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "total_num_images += num_images\n",
    "print(\"(8) 학습 이미지 갯수: \", num_images)\n",
    "print(\"(8) 총 학습 이미지 갯수: \", total_num_images)\n",
    "(x_train, y_train)=load_data(image_dir_path, num_images)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_train_total = np.concatenate([x_train_total, x_train_norm])\n",
    "y_train_total = np.concatenate([y_train_total, y_train])\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "# test data set\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_others\"\n",
    "print(\"\\n\\n(***) 테스트 이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images1=glob.glob(image_dir_path + \"/scissor/*.jpg\")\n",
    "images2=glob.glob(image_dir_path + \"/paper/*.jpg\")\n",
    "images3=glob.glob(image_dir_path + \"/rock/*.jpg\")\n",
    "num_images = len(images1) + len(images2) + len(images3)\n",
    "print(\"테스트 총 이미지 갯수: \", num_images)\n",
    "(x_test, y_test)=load_data(image_dir_path, num_images)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fb3264d873b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_channel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_channel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    196\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     return op(\n\u001b[0;32m-> 1068\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;31m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;31m# not convertible to Tensors because of mixed content.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                          as_ref=False):\n\u001b[1;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m           pywrap_tfe.TFE_ContextOptionsSetLazyRemoteInputsCopy(\n\u001b[1;32m    514\u001b[0m               opts, self._lazy_remote_inputs_copy)\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "n_channel_1=64\n",
    "n_channel_2=128\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "n_class_num = 3\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(n_class_num, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.0003),             \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_total, y_train_total, epochs=n_train_epoch)\n",
    "\n",
    "print(\"x_train_total shape: {}\".format(x_train_total.shape))\n",
    "print(\"y_train_total shape: {}\".format(y_train_total.shape))\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고찰 내용\n",
    "\n",
    "(1) 학습 & 테스트 데이터 측면\n",
    ": 9천개 정도의 충분히 데이터 양으로 학습시키고, 완전히 다른 9조의 데이터로 테스트 시켜보았더니 77% 이상의 정확도를 갖는 좋은 결과가 나왔다. \n",
    "\n",
    "(2) optimizer 파라미터 측면 \n",
    ": learning rate를 줄여서 학습하는 step을 촘촘하게 했더니 accuracy가 높아졌다 \n",
    "\n",
    "(3) Conv2D 레이어 파라미터 측면\n",
    ": n_channel_1=64, 손가락의 다양한 동작이므로 디테일하게 특징을 뽑기 위해 64개의 이미지 특징을 고려함 \n",
    ": n_channel_2=128, 그 뒤에 128개 이미지 특징씩을 고려함\n",
    ": n_dense=64, 분류기에 사용하는 뉴런의 숫자로 보다 복잡한 분류기를 만들없음\n",
    ": n_train_epoch=20, 전체 데이터를 40번 사용해서 학습을 거치는 것입니다.\n",
    ": n_class_num = 3, 최종 분류기의 클래스 수, 가위, 바위, 보 3개로 지정했음\n",
    "\n",
    "-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습/테스트 데이터 주고 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('x_train.npy',x_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/workspace'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('y_train.npy',y_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('x_test.npy',x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.load('./data/x_train.npy')\n",
    "#y_train = np.load('./data/y_train.npy')\n",
    "#x_test = np.load('./data/x_test.npy')\n",
    "#y_test = np.load('./data/y_test.npy')\n",
    "\n",
    "# shape 확인\n",
    "#x_train.shape , y_train.shape, x_test.shape , y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
